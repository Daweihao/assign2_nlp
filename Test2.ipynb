{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_characters():\n",
    "    tuples = []\n",
    "    characters = {''}\n",
    "    with open('will_play_text.csv') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=';')\n",
    "        for row in csv_reader:\n",
    "          charactor = row[4]\n",
    "          characters.add(charactor)\n",
    "          line = row[5]\n",
    "          line_tokens = re.sub(r'[^a-zA-Z0-9\\s]', ' ', line).split()\n",
    "          line_tokens = [token.lower() for token in line_tokens]\n",
    "          tuples.append((charactor, line_tokens))\n",
    "    return tuples,characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctuples,charac = read_characters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "charac.discard('')\n",
    "l_cha = list(charac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "934"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l_cha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_shakespeare():\n",
    "  '''Reads in the Shakespeare dataset processes it into a list of tuples.\n",
    "     Also reads in the vocab and play name lists from files.\n",
    "\n",
    "  Each tuple consists of\n",
    "  tuple[0]: The name of the play\n",
    "  tuple[1] A line from the play as a list of tokenized words.\n",
    "\n",
    "  Returns:\n",
    "    tuples: A list of tuples in the above format.\n",
    "    document_names: A list of the plays present in the corpus.\n",
    "    vocab: A list of all tokens in the vocabulary.\n",
    "  '''\n",
    "\n",
    "  tuples = []\n",
    "\n",
    "  with open('will_play_text.csv') as f:\n",
    "    csv_reader = csv.reader(f, delimiter=';')\n",
    "    for row in csv_reader:\n",
    "      play_name = row[1]\n",
    "      line = row[5]\n",
    "      line_tokens = re.sub(r'[^a-zA-Z0-9\\s]', ' ', line).split()\n",
    "      line_tokens = [token.lower() for token in line_tokens]\n",
    "\n",
    "      tuples.append((play_name, line_tokens))\n",
    "\n",
    "  with open('vocab.txt') as f:\n",
    "    vocab =  [line.strip() for line in f]\n",
    "\n",
    "  with open('play_names.txt') as f:\n",
    "    document_names =  [line.strip() for line in f]\n",
    "\n",
    "  return tuples, document_names, vocab\n",
    "\n",
    "def get_row_vector(matrix, row_id):\n",
    "  return matrix[row_id, :]\n",
    "\n",
    "def get_column_vector(matrix, col_id):\n",
    "  return matrix[:, col_id]\n",
    "\n",
    "def create_term_document_matrix(line_tuples, document_names, vocab):\n",
    "  '''Returns a numpy array containing the term document matrix for the input lines.\n",
    "\n",
    "  Inputs:\n",
    "    line_tuples: A list of tuples, containing the name of the document and \n",
    "    a tokenized line from that document.\n",
    "    document_names: A list of the document names\n",
    "    vocab: A list of the tokens in the vocabulary\n",
    "    \n",
    "  Let m = len(vocab) and n = len(document_names).\n",
    "\n",
    "  Returns:\n",
    "    td_matrix: A mxn numpy array where the number of rows is the number of words\n",
    "        and each column corresponds to a document. A_ij contains the\n",
    "        frequency with which word i occurs in document j.\n",
    "  '''\n",
    "\n",
    "  vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "  docname_to_id = dict(zip(document_names, range(0, len(document_names))))\n",
    "  tdm = np.zeros(shape=(len(vocab),len(document_names)))\n",
    "  for line in line_tuples:\n",
    "    doc = line[0]\n",
    "    y_axis = docname_to_id.get(doc)\n",
    "    for i in range(0,len(line[1])):\n",
    "      x_axis = vocab_to_id.get(line[1][i])\n",
    "      tdm[x_axis,y_axis] += 1\n",
    "\n",
    "  # YOUR CODE HERE\n",
    "  return tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_character_matrix(line_tuples, characters, vocab):\n",
    "    ''' Returns a numpy array containing the term character matrix for the input lines.\n",
    "    '''\n",
    "    vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "    cha_to_id = dict(zip(characters,range(0,len(characters))))\n",
    "    tdm = np.zeros(shape=(len(characters),len(vocab)))\n",
    "    for line in line_tuples:\n",
    "        cha = line[0]\n",
    "        x_axis = cha_to_id.get(cha)\n",
    "        if x_axis is None:\n",
    "            continue\n",
    "        for i in range(0,len(line[1])):\n",
    "          y_axis = vocab_to_id.get(line[1][i])\n",
    "          tdm[x_axis,y_axis] += 1\n",
    "            \n",
    "    return tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing term character matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Computing term character matrix...')\n",
    "tch_matrix = create_term_character_matrix(ctuples,charac,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tch_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_for_row = np.sum(tch_matrix,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = []\n",
    "for i in range(len(charac)):\n",
    "    if sum_for_row[i]< 1100:\n",
    "        mask.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_tc = np.delete(tc_matrix,mask,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The top most similar character to \"Second Clown\" using compute_cosine_similarity are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weihaoran/env/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Legate\n",
      "\n",
      "The top most similar character to \"Second Clown\" using compute_jaccard_similarity are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weihaoran/env/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Legate\n",
      "\n",
      "The top most similar character to \"Second Clown\" using compute_dice_similarity are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weihaoran/env/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Legate\n"
     ]
    }
   ],
   "source": [
    "random_idx = random.randint(0, len(document_names)-1)\n",
    "similarity_fns = [compute_cosine_similarity, compute_jaccard_similarity, compute_dice_similarity]\n",
    "for sim_fn in similarity_fns:\n",
    "    print('\\nThe top most similar character to \"%s\" using %s are:' % (l_cha[random_idx], sim_fn.__qualname__))\n",
    "    ranks = rank_plays(random_idx, masked_tc, sim_fn)\n",
    "    for idx in range(0, 1):\n",
    "      doc_id = ranks[idx]\n",
    "      print('%d: %s' % (idx+1, l_cha[doc_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing term document matrix...\n"
     ]
    }
   ],
   "source": [
    "tuples, document_names, vocab = read_in_shakespeare()\n",
    "\n",
    "print('Computing term document matrix...')\n",
    "td_matrix = create_term_document_matrix(tuples, document_names, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111396"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 5., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_context_matrix(line_tuples, vocab, context_window_size=1):\n",
    "  '''Returns a numpy array containing the term context matrix for the input lines.\n",
    "\n",
    "  Inputs:\n",
    "    line_tuples: A list of tuples, containing the name of the document and \n",
    "    a tokenized line from that document.\n",
    "    vocab: A list of the tokens in the vocabulary\n",
    "\n",
    "  Let n = len(vocab).\n",
    "\n",
    "  Returns:\n",
    "    tc_matrix: A nxn numpy array where A_ij contains the frequency with which\n",
    "        word j was found within context_window_size to the left or right of\n",
    "        word i in any sentence in the tuples.\n",
    "  '''\n",
    "\n",
    "  vocab_to_id = dict(zip(vocab, range(0, len(vocab))))\n",
    "\n",
    "  # YOUR CODE HERE\n",
    "  tcm = np.zeros(shape=(len(vocab),len(vocab)))\n",
    "  for line in line_tuples:\n",
    "    sent= line[1]\n",
    "    for i in range(0,len(line[1])):\n",
    "      left = i - context_window_size\n",
    "      right = i + context_window_size\n",
    "      left = 0 if left < 0 else left\n",
    "      right = len(sent) - 1 if right >= len(sent) else right\n",
    "      for j in range(left, right+1):\n",
    "        x_axis = vocab_to_id.get(sent[i],None)\n",
    "        y_axis = vocab_to_id.get(sent[j],None)\n",
    "        tcm[x_axis][y_axis] += 1\n",
    "\n",
    "  return tcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing term context matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Computing term context matrix...')\n",
    "tc_matrix = create_term_context_matrix(tuples, vocab, context_window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0., 10.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 47., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0., 23.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PPMI_matrix(term_context_matrix):\n",
    "  '''Given a term context matrix, output a PPMI matrix.\n",
    "    \n",
    "  Hint: Use numpy matrix and vector operations to speed up implementation.\n",
    "  \n",
    "  Input:\n",
    "    term_context_matrix: A nxn numpy array, where n is\n",
    "        the numer of tokens in the vocab.\n",
    "  \n",
    "  Returns: A nxn numpy matrix, where A_ij is equal to the\n",
    "     point-wise mutual information between the ith word\n",
    "     and the jth word in the term_context_matrix.\n",
    "  '''       \n",
    "  \n",
    "  # YOUR CODE HERE\n",
    "  para = term_context_matrix.shape\n",
    "  tcm = term_context_matrix.copy() + 1\n",
    "  n = para[0]\n",
    "  totals1 = np.sum(term_context_matrix)+ n * n\n",
    "  totals = np.tile(totals1,(n,para[1]))\n",
    "  ppmi = np.zeros(para)\n",
    "  rows1 = np.sum(term_context_matrix,axis=1) + n\n",
    "  rows = np.tile(rows1,(n,1)).T\n",
    "  cols1 = np.sum(term_context_matrix,axis=0) + n\n",
    "  cols = np.tile(cols1,(n,1))\n",
    "  dom = np.multiply(rows,cols)\n",
    "  num = np.multiply(totals,tcm) \n",
    "  ppmi_final = np.divide(num,dom)\n",
    "#   for i in range(0,para[0]):\n",
    "#     for j in range (0,para[1]):\n",
    "#       ppmi[i][j] = ((term_context_matrix[i][j] + 1) * totals) / (rows[i] * cols[j])\n",
    "  ppmi_final = np.log2(ppmi_final)\n",
    "  ppmi_final = np.maximum(ppmi_final, 0)\n",
    "\n",
    "  return ppmi_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PPMI matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Computing PPMI matrix...')\n",
    "PPMI_matrix = create_PPMI_matrix(tc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00954472e+00, 7.12152533e-03, 0.00000000e+00, ...,\n",
       "        9.41708477e-03, 9.41708477e-03, 2.79540916e-03],\n",
       "       [7.12152533e-03, 3.46412995e+00, 0.00000000e+00, ...,\n",
       "        6.99388708e-03, 6.99388708e-03, 3.72211475e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 5.57174896e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.41708477e-03, 6.99388708e-03, 0.00000000e+00, ...,\n",
       "        1.00928945e+00, 9.28944653e-03, 2.66777092e-03],\n",
       "       [9.41708477e-03, 6.99388708e-03, 0.00000000e+00, ...,\n",
       "        9.28944653e-03, 1.00928945e+00, 2.66777092e-03],\n",
       "       [2.79540916e-03, 3.72211475e-04, 0.00000000e+00, ...,\n",
       "        2.66777092e-03, 2.66777092e-03, 4.58100860e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPMI_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00954472e+00, 7.12152533e-03, 0.00000000e+00, ...,\n",
       "        9.41708477e-03, 9.41708477e-03, 2.79540916e-03],\n",
       "       [7.12152533e-03, 3.46412995e+00, 0.00000000e+00, ...,\n",
       "        6.99388708e-03, 6.99388708e-03, 3.72211475e-04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 5.57174896e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.41708477e-03, 6.99388708e-03, 0.00000000e+00, ...,\n",
       "        1.00928945e+00, 9.28944653e-03, 2.66777092e-03],\n",
       "       [9.41708477e-03, 6.99388708e-03, 0.00000000e+00, ...,\n",
       "        9.28944653e-03, 1.00928945e+00, 2.66777092e-03],\n",
       "       [2.79540916e-03, 3.72211475e-04, 0.00000000e+00, ...,\n",
       "        2.66777092e-03, 2.66777092e-03, 4.58100860e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPMI_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_idf_matrix(term_document_matrix):\n",
    "  '''Given the term document matrix, output a tf-idf weighted version.\n",
    "  \n",
    "  Hint: Use numpy matrix and vector operations to speed up implementation.\n",
    "\n",
    "  Input:\n",
    "    term_document_matrix: Numpy array where each column represents a document \n",
    "    and each row, the frequency of a word in that document.\n",
    "\n",
    "  Returns:\n",
    "    A numpy array with the same dimension as term_document_matrix, where\n",
    "    A_ij is weighted by the inverse document frequency of document h.\n",
    "  '''\n",
    "\n",
    "  # YOUR CODE HERE\n",
    "  tf_idf_matrix = np.zeros(term_document_matrix.shape)\n",
    "  df_raw = term_document_matrix.copy()\n",
    "  tf_raw = term_document_matrix.copy()\n",
    "  df_raw[df_raw > 0] = 1\n",
    "  df = np.sum(df_raw,axis=1)\n",
    "  docs = term_document_matrix.shape[1]\n",
    "  idf = np.log(docs/df[df>0])\n",
    "\n",
    "  tf_raw[tf_raw>0] = np.log10(tf_raw[tf_raw>0])+1\n",
    "\n",
    "  tf = tf_raw\n",
    "\n",
    "  for row in range(idf.shape[0]):\n",
    "      tf_idf_matrix[row] = tf[row] * idf[row]\n",
    "\n",
    "  return tf_idf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing tf-idf matrix...\n"
     ]
    }
   ],
   "source": [
    "print('Computing tf-idf matrix...')\n",
    "tf_idf_matrix = create_tf_idf_matrix(td_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 2.19722458, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.17763627, 0.        , ..., 0.69314718, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.28093385, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(vector1, vector2):\n",
    "  '''Computes the cosine similarity of the two input vectors.\n",
    "\n",
    "  Inputs:\n",
    "    vector1: A nx1 numpy array\n",
    "    vector2: A nx1 numpy array\n",
    "\n",
    "  Returns:\n",
    "    A scalar similarity value.\n",
    "  '''\n",
    "  cs = np.dot(vector1,vector2)/(LA.norm(vector1)*LA.norm(vector2))\n",
    "  # YOUR CODE HERE\n",
    "  return cs\n",
    "\n",
    "def compute_jaccard_similarity(vector1, vector2):\n",
    "  '''Computes the cosine similarity of the two input vectors.\n",
    "\n",
    "  Inputs:\n",
    "    vector1: A nx1 numpy array\n",
    "    vector2: A nx1 numpy array\n",
    "\n",
    "  Returns:\n",
    "    A scalar similarity value.\n",
    "  '''\n",
    "  \n",
    "  # YOUR CODE HERE\n",
    "  num = np.minimum(vector1,vector2)\n",
    "  dom = np.maximum(vector1,vector2)\n",
    "  js = np.sum(num)/np.sum(dom)\n",
    "\n",
    "  return js\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_similarity(vector1, vector2):\n",
    "  '''Computes the cosine similarity of the two input vectors.\n",
    "\n",
    "  Inputs:\n",
    "    vector1: A nx1 numpy array\n",
    "    vector2: A nx1 numpy array\n",
    "\n",
    "  Returns:\n",
    "    A scalar similarity value.\n",
    "  '''\n",
    "\n",
    "  # YOUR CODE HERE\n",
    "  upper = np.minimum(vector1,vector2)\n",
    "  upper_sum = np.sum(upper) * 2\n",
    "  dom = np.sum(vector1 + vector2)\n",
    "  return upper_sum/dom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_plays(target_play_index, term_document_matrix, similarity_fn):\n",
    "  ''' Ranks the similarity of all of the plays to the target play.\n",
    "\n",
    "  Inputs:\n",
    "    target_play_index: The integer index of the play we want to compare all others against.\n",
    "    term_document_matrix: The term-document matrix as a mxn numpy array.\n",
    "    similarity_fn: Function that should be used to compared vectors for two\n",
    "      documents. Either compute_dice_similarity, compute_jaccard_similarity, or\n",
    "      compute_cosine_similarity.\n",
    "\n",
    "  Returns:\n",
    "    A length-n list of integer indices corresponding to play names,\n",
    "    ordered by decreasing similarity to the play indexed by target_play_index\n",
    "  '''\n",
    "  \n",
    "  # YOUR CODE HERE\n",
    "  nums = term_document_matrix.shape[1]\n",
    "  target = term_document_matrix.T[target_play_index,:]\n",
    "  docs_ranking = {}\n",
    "  result = []\n",
    "  td_in_cols = term_document_matrix.T\n",
    "  for i in range(nums):\n",
    "          if i!= target_play_index:\n",
    "              similarity_doc = similarity_fn(td_in_cols[i,:], target)\n",
    "              docs_ranking[i] = similarity_doc\n",
    "  sort_ranking = sorted(docs_ranking.items(),key=lambda item: item[1],reverse=True)\n",
    "  for k,v in sort_ranking:\n",
    "      result.append(k)\n",
    "  return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_words(target_word_index, matrix, similarity_fn):\n",
    "  ''' Ranks the similarity of all of the words to the target word.\n",
    "\n",
    "  Inputs:\n",
    "    target_word_index: The index of the word we want to compare all others against.\n",
    "    matrix: Numpy matrix where the ith row represents a vector embedding of the ith word.\n",
    "    similarity_fn: Function that should be used to compared vectors for two word\n",
    "      ebeddings. Either compute_dice_similarity, compute_jaccard_similarity, or\n",
    "      compute_cosine_similarity.\n",
    "\n",
    "  Returns:\n",
    "    A length-n list of integer word indices, ordered by decreasing similarity to the \n",
    "    target word indexed by word_index\n",
    "  '''\n",
    "\n",
    "  # YOUR CODE HERE\n",
    "  result =[]\n",
    "  nums = matrix.shape[0]\n",
    "  target = matrix[target_word_index,:]\n",
    "  word_ranking = {}\n",
    "  for i in range(nums):\n",
    "      if i!= target_word_index:\n",
    "        word_simi = similarity_fn(matrix[i,:],target)\n",
    "        word_ranking[i] = word_simi\n",
    "  for k,v in sorted(word_ranking.items(),key=lambda item: item[1],reverse=True):\n",
    "      result.append(k)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randint(0, len(document_names)-1)\n",
    "similarity_fns = [compute_cosine_similarity, compute_jaccard_similarity, compute_dice_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The top most similar plays to \"Henry V\" using compute_cosine_similarity are:\n",
      "1: King John\n",
      "\n",
      "The top most similar plays to \"Henry V\" using compute_jaccard_similarity are:\n",
      "1: Henry IV\n",
      "\n",
      "The top most similar plays to \"Henry V\" using compute_dice_similarity are:\n",
      "1: Henry IV\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_cosine_similarity on term-document frequency matrix are:\n",
      "1: capulet\n",
      "2: pump\n",
      "3: laura\n",
      "4: pitcher\n",
      "5: behoveful\n",
      "6: hurdle\n",
      "7: capulets\n",
      "8: petrucio\n",
      "9: heartless\n",
      "10: searchers\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_jaccard_similarity on term-document frequency matrix are:\n",
      "1: tybalt\n",
      "2: capulet\n",
      "3: nurse\n",
      "4: romeo\n",
      "5: mercutio\n",
      "6: friar\n",
      "7: montague\n",
      "8: laurence\n",
      "9: paris\n",
      "10: peter\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_dice_similarity on term-document frequency matrix are:\n",
      "1: tybalt\n",
      "2: capulet\n",
      "3: nurse\n",
      "4: romeo\n",
      "5: mercutio\n",
      "6: friar\n",
      "7: montague\n",
      "8: laurence\n",
      "9: paris\n",
      "10: peter\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_cosine_similarity on term-context frequency matrix are:\n",
      "1: and\n",
      "2: drinkings\n",
      "3: pined\n",
      "4: metheglins\n",
      "5: scamble\n",
      "6: groaning\n",
      "7: bleated\n",
      "8: cymbals\n",
      "9: grunt\n",
      "10: clasping\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_jaccard_similarity on term-context frequency matrix are:\n",
      "1: silvia\n",
      "2: nurse\n",
      "3: orlando\n",
      "4: proteus\n",
      "5: othello\n",
      "6: demetrius\n",
      "7: leonato\n",
      "8: hamlet\n",
      "9: marcus\n",
      "10: wake\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_dice_similarity on term-context frequency matrix are:\n",
      "1: silvia\n",
      "2: nurse\n",
      "3: orlando\n",
      "4: proteus\n",
      "5: othello\n",
      "6: demetrius\n",
      "7: leonato\n",
      "8: hamlet\n",
      "9: marcus\n",
      "10: wake\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_cosine_similarity on tf-idf matrix are:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weihaoran/env/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: capulet\n",
      "2: bedaub\n",
      "3: howlings\n",
      "4: demesnes\n",
      "5: scaring\n",
      "6: furred\n",
      "7: umpire\n",
      "8: hilding\n",
      "9: nobleman\n",
      "10: busied\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_jaccard_similarity on tf-idf matrix are:\n",
      "1: benvolio\n",
      "2: lucio\n",
      "3: mercutio\n",
      "4: capulet\n",
      "5: tybalt\n",
      "6: romeo\n",
      "7: capulets\n",
      "8: ghostly\n",
      "9: montagues\n",
      "10: procures\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_dice_similarity on tf-idf matrix are:\n",
      "1: benvolio\n",
      "2: lucio\n",
      "3: mercutio\n",
      "4: capulet\n",
      "5: tybalt\n",
      "6: romeo\n",
      "7: capulets\n",
      "8: ghostly\n",
      "9: montagues\n",
      "10: procures\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_cosine_similarity on PPMI matrix are:\n",
      "1: nurse\n",
      "2: tybalt\n",
      "3: capulet\n",
      "4: romeo\n",
      "5: mistress\n",
      "6: lady\n",
      "7: silvia\n",
      "8: provost\n",
      "9: dead\n",
      "10: waken\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_jaccard_similarity on PPMI matrix are:\n",
      "1: silvia\n",
      "2: nurse\n",
      "3: tybalt\n",
      "4: capulet\n",
      "5: proteus\n",
      "6: hamlet\n",
      "7: leonato\n",
      "8: romeo\n",
      "9: orlando\n",
      "10: cassio\n",
      "\n",
      "The 10 most similar words to \"juliet\" using compute_dice_similarity on PPMI matrix are:\n",
      "1: silvia\n",
      "2: nurse\n",
      "3: tybalt\n",
      "4: capulet\n",
      "5: proteus\n",
      "6: hamlet\n",
      "7: leonato\n",
      "8: romeo\n",
      "9: orlando\n",
      "10: cassio\n"
     ]
    }
   ],
   "source": [
    "  for sim_fn in similarity_fns:\n",
    "    print('\\nThe top most similar plays to \"%s\" using %s are:' % (document_names[random_idx], sim_fn.__qualname__))\n",
    "    ranks = rank_plays(random_idx, td_matrix, sim_fn)\n",
    "    for idx in range(0, 1):\n",
    "      doc_id = ranks[idx]\n",
    "      print('%d: %s' % (idx+1, document_names[doc_id]))\n",
    "\n",
    "  word = 'juliet'\n",
    "  vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "  for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar words to \"%s\" using %s on term-document frequency matrix are:' % (word, sim_fn.__qualname__))\n",
    "    ranks = rank_words(vocab_to_index[word], td_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "      word_id = ranks[idx]\n",
    "      print('%d: %s' % (idx+1, vocab[word_id]))\n",
    "\n",
    "  word = 'juliet'\n",
    "  vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "  for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar words to \"%s\" using %s on term-context frequency matrix are:' % (word, sim_fn.__qualname__))\n",
    "    ranks = rank_words(vocab_to_index[word], tc_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "      word_id = ranks[idx]\n",
    "      print('%d: %s' % (idx+1, vocab[word_id]))\n",
    "\n",
    "  word = 'juliet'\n",
    "  vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "  for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar words to \"%s\" using %s on tf-idf matrix are:' % (word, sim_fn.__qualname__))\n",
    "    ranks = rank_words(vocab_to_index[word], tf_idf_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "      word_id = ranks[idx]\n",
    "      print('%d: %s' % (idx+1, vocab[word_id]))\n",
    "\n",
    "  word = 'juliet'\n",
    "  vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
    "  for sim_fn in similarity_fns:\n",
    "    print('\\nThe 10 most similar words to \"%s\" using %s on PPMI matrix are:' % (word, sim_fn.__qualname__))\n",
    "    ranks = rank_words(vocab_to_index[word], PPMI_matrix, sim_fn)\n",
    "    for idx in range(0, 10):\n",
    "      word_id = ranks[idx]\n",
    "      print('%d: %s' % (idx+1, vocab[word_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import sklearn.cluster as cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Henry IV',\n",
       " 'Alls well that ends well',\n",
       " 'Loves Labours Lost',\n",
       " 'Taming of the Shrew',\n",
       " 'Antony and Cleopatra',\n",
       " 'Coriolanus',\n",
       " 'Hamlet',\n",
       " 'A Midsummer nights dream',\n",
       " 'Merry Wives of Windsor',\n",
       " 'Romeo and Juliet',\n",
       " 'Richard II',\n",
       " 'King John',\n",
       " 'macbeth',\n",
       " 'Timon of Athens',\n",
       " 'A Winters Tale',\n",
       " 'The Tempest',\n",
       " 'Henry VI Part 2',\n",
       " 'As you like it',\n",
       " 'Julius Caesar',\n",
       " 'A Comedy of Errors',\n",
       " 'Henry VIII',\n",
       " 'Measure for measure',\n",
       " 'Richard III',\n",
       " 'Two Gentlemen of Verona',\n",
       " 'Henry VI Part 1',\n",
       " 'Much Ado about nothing',\n",
       " 'Henry V',\n",
       " 'Troilus and Cressida',\n",
       " 'Twelfth Night',\n",
       " 'Merchant of Venice',\n",
       " 'Henry VI Part 3',\n",
       " 'Othello',\n",
       " 'Cymbeline',\n",
       " 'King Lear',\n",
       " 'Pericles',\n",
       " 'Titus Andronicus']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tragedies = {'Troilus and Cressida',\n",
    "'Coriolanus',\n",
    "'Titus Andronicus',\n",
    "'Romeo and Juliet',\n",
    "'Timon of Athens',\n",
    "'Julius Caesar',\n",
    "'macbeth',\n",
    "'Hamlet',\n",
    "'King Lear',\n",
    "'Othello',\n",
    "'Antony and Cleopatra',\n",
    "'Cymbeline'}\n",
    "Histories = {'King John',\n",
    "'Richard II',\n",
    "'Henry IV',\n",
    "'Henry V',\n",
    "'Henry VI Part 1',\n",
    "'Henry VI Part 2',\n",
    "'Henry VI Part 3',\n",
    "'Richard III',\n",
    "'Henry VIII',\n",
    "'Edward III'}\n",
    "Comedies = {'The Tempest',\n",
    "'Two Gentlemen of Verona',\n",
    "'Merry Wives of Windsor',\n",
    "'Measure for measure',\n",
    "'A Comedy of Errors',\n",
    "'Much Ado about nothing',\n",
    "'Loves Labours Lost',\n",
    "'A Midsummer nights dream',\n",
    "'Merchant of Venice',\n",
    "'As you like it',\n",
    "'Taming of the Shrew',\n",
    "'Alls well that ends well',\n",
    "'Twelfth Night',\n",
    "'A Winters Tale', \n",
    "'Pericles'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags notation: 0 stands for **Comedies**, 1 stands for **Histories** and 2 stands for **Tragedies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = []\n",
    "for i in range(len(document_names)):\n",
    "    if document_names[i] in Tragedies:\n",
    "        flags.append(2)\n",
    "    if document_names[i] in Histories:\n",
    "        flags.append(1)\n",
    "    if document_names[i] in Comedies:\n",
    "        flags.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++')\n",
    "kmeans.fit_predict(td_matrix.T)\n",
    "pred_km = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 0, 1,\n",
       "       0, 2, 2, 1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tragedies:Henry IV\n",
      "Histories:Alls well that ends well\n",
      "Histories:Loves Labours Lost\n",
      "Histories:Taming of the Shrew\n",
      "Tragedies:Antony and Cleopatra\n",
      "Tragedies:Coriolanus\n",
      "Tragedies:Hamlet\n",
      "Comedies: A Midsummer nights dream\n",
      "Histories:Merry Wives of Windsor\n",
      "Histories:Romeo and Juliet\n",
      "Comedies: Richard II\n",
      "Comedies: King John\n",
      "Comedies: macbeth\n",
      "Comedies: Timon of Athens\n",
      "Tragedies:A Winters Tale\n",
      "Comedies: The Tempest\n",
      "Tragedies:Henry VI Part 2\n",
      "Histories:As you like it\n",
      "Comedies: Julius Caesar\n",
      "Comedies: A Comedy of Errors\n",
      "Tragedies:Henry VIII\n",
      "Histories:Measure for measure\n",
      "Tragedies:Richard III\n",
      "Comedies: Two Gentlemen of Verona\n",
      "Comedies: Henry VI Part 1\n",
      "Histories:Much Ado about nothing\n",
      "Tragedies:Henry V\n",
      "Tragedies:Troilus and Cressida\n",
      "Histories:Twelfth Night\n",
      "Histories:Merchant of Venice\n",
      "Tragedies:Henry VI Part 3\n",
      "Tragedies:Othello\n",
      "Tragedies:Cymbeline\n",
      "Tragedies:King Lear\n",
      "Comedies: Pericles\n",
      "Comedies: Titus Andronicus\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred_km)):\n",
    "    if pred_km[i] ==2:\n",
    "        print(\"Comedies: \"+document_names[i])\n",
    "    elif pred_km[i] == 0:\n",
    "        print(\"Tragedies:\"+document_names[i])\n",
    "    else :print(\"Histories:\" + document_names[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
